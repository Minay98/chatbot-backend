from fastapi import FastAPI, File, Path, UploadFile, HTTPException,Depends
from pydantic import BaseModel
from langchain_ollama import OllamaEmbeddings, OllamaLLM
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain_community.vectorstores import Chroma
from langchain_community.document_loaders import TextLoader
from langchain.prompts import PromptTemplate
from fastapi.middleware.cors import CORSMiddleware
from sqlmodel import Session, select
from models import ChatHistory, SessionLimit, UploadedFile
from sqlalchemy import delete
from datetime import datetime
import logging
from typing import List
import os
import uuid
from langchain.document_loaders import TextLoader
from langchain.document_loaders import (
    TextLoader,
    PyMuPDFLoader,
    CSVLoader,
    UnstructuredExcelLoader,UnstructuredWordDocumentLoader
)
from auth import router as auth_router
import chromadb
from models import UploadedFile
from fastapi import Request
from fastapi import FastAPI
from db import engine 
from db import get_session
from db import create_db_and_tables
from langchain_core.documents import Document  # Ø§Ú¯Ø± Ù‚Ø¨Ù„Ø§Ù‹ import Ù†Ø´Ø¯Ù‡
from langchain_ollama import OllamaEmbeddings
from langchain_community.vectorstores import Chroma
from models import Admin
from auth import router as auth_router
from auth import get_password_hash, get_current_admin
UPLOAD_DIR = "./uploaded_files"
chromadb.config.Settings(anonymized_telemetry=False)


app = FastAPI()

app.include_router(auth_router)


logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
create_db_and_tables()

def create_admin_user():
    with get_session() as session:
        exists = session.exec(select(Admin).where(Admin.email == "admin@example.com")).first()
        if not exists:
            admin = Admin(email="admin@example.com", password_hash=get_password_hash("123456"))
            session.add(admin)
            session.commit()

create_admin_user()

# ØªØ³Øª Ù…Ø³ÛŒØ± Ù…Ø­Ø§ÙØ¸Øªâ€ŒØ´Ø¯Ù‡
@app.get("/admin/me")
def read_admin(current_admin: str = Depends(get_current_admin)):
    return {"email": current_admin}


class LoginRequest(BaseModel):
    email: str
    password: str

class TokenResponse(BaseModel):
    access_token: str
    token_type: str = "bearer"
    
    
def rebuild_chroma():
    logger.info("ğŸ“¦ Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ Chroma vector store Ù¾Ø³ Ø§Ø² Ø­Ø°Ù")

    embedding = OllamaEmbeddings(
        model="dengcao/Qwen3-Embedding-4B:Q8_0",
        base_url="http://192.168.90.20:7869/"
    )

    session = get_session()
    files = session.exec(select(UploadedFile)).all()

    all_docs = []
    for file in files:
        try:
            file_path = file.filepath
            ext = os.path.splitext(file.filename)[-1].lower()
            if not os.path.exists(file_path):
                continue

            if ext == ".pdf":
                loader = PyMuPDFLoader(file_path)
            elif ext in [".xls", ".xlsx"]:
                loader = UnstructuredExcelLoader(file_path)
            elif ext in [".doc", ".docx"]:
                loader = UnstructuredWordDocumentLoader(file_path)
            elif ext == ".csv":
                loader = CSVLoader(file_path, encoding="utf-8")
            else:
                loader = TextLoader(file_path, encoding="utf-8")

            documents = loader.load()
            splitter = RecursiveCharacterTextSplitter(chunk_size=256, chunk_overlap=50)
            split_docs = splitter.split_documents(documents)

            docs_with_meta = [
                Document(page_content=doc.page_content, metadata={"filename": file.filename})
                for doc in split_docs
            ]
            all_docs.extend(docs_with_meta)
        except Exception as e:
            logger.warning(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ ÙØ§ÛŒÙ„ {file.filename}: {e}")

    # Ø­Ø°Ù Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù‚Ø¨Ù„ÛŒ
    import shutil
    if os.path.exists("./chroma_db"):
        shutil.rmtree("./chroma_db")

    # Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ Ú©Ø§Ù…Ù„
    Chroma.from_documents(
        documents=all_docs,
        embedding=embedding,
        persist_directory="./chroma_db"
    )
    

    logger.info("âœ… Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ Ø´Ø¯Ù†Ø¯.")


def add_history(question: str, answer: str, session_id: str):
    with Session(engine) as session:
        session.add(ChatHistory(question=question, answer=answer, session_id=session_id))
        session.commit()
# Load document function
def load_createDoc(doc_path="doc.txt"):
    try:
        loader = TextLoader(doc_path, encoding="utf-8")
        documents = loader.load()
        if not documents:
            raise ValueError("ÙØ§ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ù†Ø¯Ø§Ø±Ø¯ ÛŒØ§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")
        splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=200)
        docs = splitter.split_documents(documents)
        return docs
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙˆÚ©ØªÙˆØ±Ù‡Ø§: {e}")
        raise
# Load document function
def load_vectorstore(docs):
    try:
        embedding = OllamaEmbeddings(
            model="dengcao/Qwen3-Embedding-4B:Q8_0",
            base_url="http://192.168.90.20:7869/"
        )
        vectordb = Chroma.from_documents(
            documents=docs,
            embedding=embedding,
            persist_directory="./chroma_db"
        )

        return vectordb.as_retriever()
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙˆÚ©ØªÙˆØ±Ù‡Ø§: {e}")
        raise
    
    
    

llm = OllamaLLM(model="gemma3n:latest", base_url="http://192.168.90.20:7869/", name="mina ai")
prompt = PromptTemplate(
    template="""
Ø´Ù…Ø§ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ù‡Ø³ØªÛŒØ¯ Ú©Ù‡ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø³Ø§Ø¯Ù‡ Ùˆ Ø¯Ù‚ÛŒÙ‚ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒØ¯.
Ø§Ú¯Ø± Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ Ù†Ø¯Ø§Ø´ØªÛŒ ÛŒØ§ Ù†Ù…ÛŒØ¯ÙˆÙ†Ø³ØªÛŒ ÙÙ‚Ø· Ø¨Ú¯Ùˆ Ú©Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ Ù†Ø¯Ø§Ø±Ù…. Ù‡Ù…Ú†Ù†ÛŒÙ† Ø§Ú¯Ø± 
Ù„Ø·ÙØ§Ù‹ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³ÙˆØ§Ù„ Ø²ÛŒØ± Ùˆ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø´Ø¯Ù‡ Ù¾Ø§Ø³Ø® Ø¨Ø¯Ù‡:
Ø³ÙˆØ§Ù„: {question}
=========
Ø§Ø·Ù„Ø§Ø¹Ø§Øª:
{context}
=========
Ù¾Ø§Ø³Ø®:""",
    input_variables=["question", "context"]
)

class Question(BaseModel):
    question: str
    
    
def get_qa_chain():
    embedding = OllamaEmbeddings(
        model="dengcao/Qwen3-Embedding-4B:Q8_0",
        base_url="http://192.168.90.20:7869/"
    )
    retriever1 = Chroma(
        persist_directory="./chroma_db",
        embedding_function=embedding
    ).as_retriever()

    return RetrievalQA.from_chain_type(
        llm=llm,
        retriever=retriever1,
        return_source_documents=True,
        chain_type_kwargs={"prompt": prompt}
    )

    

@app.get("/get_session_id")
def get_session_id():
    session_id = str(uuid.uuid4())
    return {"session_id": session_id}
#########################################################################      
class AskRequest(BaseModel):
    question: str
    session_id: str
    
@app.post("/ask")
def ask(req: AskRequest, request: Request):
    try:
        session_id = req.session_id
        question = req.question
        user_ip = request.client.host  

        print("âœ… session_id:", session_id)
        print("âœ… user_ip:", user_ip)

        with Session(engine) as session:
            # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø¨Ø± Ø§Ø³Ø§Ø³ session_id

            limit = session.exec(
    select(SessionLimit).where(SessionLimit.session_id == session_id)
).first()

            if not limit:
                limit = SessionLimit(
                    session_id=session_id,
                    ip=user_ip,
                    message_count=0,
                    last_message_time=datetime.utcnow()
                )
                session.add(limit)
                session.commit()
                session.refresh(limit)
       

            if limit.message_count >= 50:
                raise HTTPException(status_code=403, detail="Ø¨Ù‡ Ø³Ù‚Ù Ù…Ø¬Ø§Ø² Ù¾ÛŒØ§Ù… Ø±Ø³ÛŒØ¯Ù‡â€ŒØ§ÛŒØ¯.")

            # Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø¯Ù„
            qa_chain = get_qa_chain()
            result = qa_chain.invoke({"query": question})
            answer = result.get("result", "")
            sources = result.get("source_documents", [])

            if not sources:
                answer = "âŒ Ù¾Ø§Ø³Ø® Ø§ÛŒÙ† Ø³Ø¤Ø§Ù„ Ø¯Ø± Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ù† Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª ÛŒØ§ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø­ÙˆØ²Ù‡ Ú©Ø§Ø±ÛŒ Ù…Ù† Ù†Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯."

            # Ø°Ø®ÛŒØ±Ù‡ ØªØ§Ø±ÛŒØ®Ú†Ù‡
            add_history(question=question, answer=answer, session_id=session_id)
            limit.message_count += 1
            session.commit()

        return {"question": question, "answer": answer}

    except HTTPException as http_exc:
        raise http_exc

    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± /ask: {e}")
        raise HTTPException(status_code=500, detail="Ø®Ø·Ø§ÛŒ Ø¯Ø§Ø®Ù„ÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø¯Ù„")
#########################################################################      
@app.get("/history")
def get_history():
    with Session(engine) as session:
        chats = session.exec(select(ChatHistory).order_by(ChatHistory.timestamp.desc())).all()
        return [
            {
                "question": chat.question,
                "answer": chat.answer,
                "timestamp": chat.timestamp.strftime("%Y-%m-%d %H:%M") if chat.timestamp else None
            }
            for chat in chats
        ]
#########################################################################      
@app.delete("/history")
def delete_history(session_id: str):
    with Session(engine) as session:
        session.exec(
            delete(ChatHistory).where(ChatHistory.session_id == session_id)
        )
        session.commit()
    return {"message": "ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú¯ÙØªÚ¯Ùˆ Ø­Ø°Ù Ø´Ø¯."}
#########################################################################      

@app.post("/upload")
async def upload_files(files: List[UploadFile] = File(...)):
    try:
        all_docs = []
        uploaded_files = []
        skipped_files = []

        embedding = OllamaEmbeddings(
            model="dengcao/Qwen3-Embedding-4B:Q8_0",
            base_url="http://192.168.90.20:7869/"
        )

        session = get_session()

        if os.path.exists("./chroma_db"):
            vectordb = Chroma(persist_directory="./chroma_db", embedding_function=embedding)
        else:
            vectordb = Chroma.from_documents([], embedding=embedding, persist_directory="./chroma_db")

        for file in files:
            try:
                # Ø¨Ø±Ø±Ø³ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ Ø¨ÙˆØ¯Ù†
                existing_file = session.exec(
                    select(UploadedFile).where(UploadedFile.filename == file.filename)
                ).first()
                if existing_file:
                    logger.warning(f"âš ï¸ ÙØ§ÛŒÙ„ ØªÚ©Ø±Ø§Ø±ÛŒ Ø±Ø¯ Ø´Ø¯: {file.filename}")
                    skipped_files.append(file.filename)
                    continue

                content = await file.read()
                if not content:
                    raise HTTPException(status_code=400, detail=f"âŒ ÙØ§ÛŒÙ„ {file.filename} Ø®Ø§Ù„ÛŒ Ø§Ø³Øª.")

                file_path = os.path.join(UPLOAD_DIR, file.filename)
                with open(file_path, "wb") as f:
                    f.write(content)

                ext = os.path.splitext(file.filename)[-1].lower()
                if ext not in [".txt", ".pdf", ".xls", ".xlsx", ".doc", ".docx", ".csv"]:
                    logger.warning(f"ğŸ“‚ ÙØ±Ù…Øª ÙØ§ÛŒÙ„ {file.filename} Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯. ÙÙ‚Ø· Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")
                    uploaded_files.append(file.filename)
                    continue

                if ext == ".pdf":
                    loader = PyMuPDFLoader(file_path)
                elif ext in [".xls", ".xlsx"]:
                    loader = UnstructuredExcelLoader(file_path)
                elif ext in [".doc", ".docx"]:
                    loader = UnstructuredWordDocumentLoader(file_path)
                elif ext == ".csv":
                    loader = CSVLoader(file_path, encoding="utf-8")
                else:
                    loader = TextLoader(file_path, encoding="utf-8")

                documents = loader.load()
                splitter = RecursiveCharacterTextSplitter(chunk_size=256, chunk_overlap=50)
                split_docs = splitter.split_documents(documents)

                # ØªØ³Øª Ø§ÙˆÙ„ÛŒÙ‡ embed
                test_embed = embedding.embed_query(split_docs[0].page_content)
                if not test_embed or len(test_embed) == 0:
                    logger.warning(f"ğŸš« Ù…Ø¯Ù„ embedding Ù¾Ø§Ø³Ø® Ù†Ø¯Ø§Ø¯ Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„: {file.filename}")
                    skipped_files.append(file.filename)
                    os.remove(file_path)  # Ø­Ø°Ù ÙØ§ÛŒÙ„ Ø§Ø² ÙØ§ÛŒÙ„â€ŒØ³ÛŒØ³ØªÙ…
                    continue  # Ø±Ø¯ Ú©Ø±Ø¯Ù† Ø§ÛŒÙ† ÙØ§ÛŒÙ„

                docs_with_metadata = [
                    Document(page_content=doc.page_content, metadata={"filename": file.filename})
                    for doc in split_docs
                ]

                # Ø«Ø¨Øª Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ (Ø¨Ø¹Ø¯ Ø§Ø² ØªØ£ÛŒÛŒØ¯ Ø³Ø§Ù„Ù… Ø¨ÙˆØ¯Ù† embedding)
                file_record = UploadedFile(filename=file.filename, filepath=file_path)
                session.add(file_record)

                vectordb.add_documents(docs_with_metadata)

                logger.info(f"âœ… ÙØ§ÛŒÙ„: {file.filename} - Ø¨Ø®Ø´â€ŒÙ‡Ø§: {len(split_docs)}")
                all_docs.extend(split_docs)
                uploaded_files.append(file.filename)

            except UnicodeDecodeError as ude:
                logger.error(f"âŒ Ø®Ø·Ø§ÛŒ encoding Ø¯Ø± ÙØ§ÛŒÙ„ {file.filename}: {ude}")
                raise HTTPException(status_code=400, detail=f"Ø®Ø·Ø§ÛŒ encoding Ø¯Ø± ÙØ§ÛŒÙ„ {file.filename}")
            except Exception as e:
                logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ {file.filename}: {e}")
                raise HTTPException(status_code=400, detail=f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ {file.filename}")

        session.commit()
        session.close()

        return {
            "message": "ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ø§Ù…Ù„ Ø´Ø¯.",
            "uploaded_files": uploaded_files,
            "skipped_duplicates": skipped_files,
            "total_docs_added": len(all_docs)
        }

    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§: {e}")
        raise HTTPException(status_code=500, detail="Ø®Ø·Ø§ÛŒ Ø¯Ø§Ø®Ù„ÛŒ Ø¯Ø± Ù‡Ù†Ú¯Ø§Ù… Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§")


#########################################################################          
@app.get("/files")
def list_uploaded_files():
    directory = UPLOAD_DIR  # Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ØŒ Ù…Ø«Ù„Ø§Ù‹ /uploads ÛŒØ§ ./files
    files = []
    for filename in os.listdir(directory):
        files.append(filename)
    return {"files": files}
#########################################################################          
@app.delete("/files/{filename}")
def delete_file(filename: str = Path(...)):
    file_path = os.path.join(UPLOAD_DIR, filename)
    session = get_session()

    if os.path.exists(file_path):
        os.remove(file_path)

    # Ø­Ø°Ù Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³
    file_record = session.exec(
        select(UploadedFile).where(UploadedFile.filename == filename)
    ).first()

    if file_record:
        session.delete(file_record)
        session.commit()

    # Ø­Ø°Ù Ø§Ø² Chroma
    try:
        embedding = OllamaEmbeddings(
            model="dengcao/Qwen3-Embedding-4B:Q8_0",
            base_url="http://192.168.90.20:7869/"
        )
        vectordb = Chroma(
            persist_directory="./chroma_db",
            embedding_function=embedding
        )

        vectordb._collection.delete(where={"filename": filename})  # âœ… Ø­Ø°Ù Ø¯Ù‚ÛŒÙ‚
        vectordb.persist()  # âœ… Ø°Ø®ÛŒØ±Ù‡ ØªØºÛŒÛŒØ±Ø§Øª

        logger.info(f"âœ… Ø§Ø³Ù†Ø§Ø¯ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ {filename} Ø§Ø² Ø¨Ø±Ø¯Ø§Ø± Ø­Ø°Ù Ø´Ø¯Ù†Ø¯.")

    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø­Ø°Ù Ø§Ø³Ù†Ø§Ø¯ Ø§Ø² ChromaDB: {e}")

    return {"message": f"{filename} Ø§Ø² Ù‡Ù…Ù‡â€ŒØ¬Ø§ Ø­Ø°Ù Ø´Ø¯."}


#########################################################################      
@app.get("/chat/{session_id}")
def get_chat(session_id: str):
    with Session(engine) as session:
        history = session.exec(
            select(ChatHistory).where(ChatHistory.session_id == session_id)
        ).all()
        return [
            {
                "question": msg.question,
                "answer": msg.answer,
                "timestamp": msg.timestamp.isoformat()
            }
            for msg in history
        ]
        
####################################################################
